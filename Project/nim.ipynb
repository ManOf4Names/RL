{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from policy import *\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "newGame = [1, 3, 5, 7]\n",
    "\n",
    "win = (0, 0, 0, 0)\n",
    "\n",
    "Gamma = 0.9\n",
    "\n",
    "# Reward values for win and loss conditions\n",
    "win_reward = 100\n",
    "lose_reward = -50\n",
    "\n",
    "# episode length\n",
    "gameRunning = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Initialize():\n",
    "    global policy\n",
    "    global value\n",
    "    global Q\n",
    "    policy = copy.deepcopy(Policy_Template) #replaced .copy with a deepcopy\n",
    "    value = copy.deepcopy(Value_Template)\n",
    "    Q = copy.deepcopy(Q_Template)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def New_Game():\n",
    "    global state\n",
    "    state = copy.deepcopy(newGame)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A function for setting the policy for a given state\n",
    "    r1: Number of sticks in row 1\n",
    "    r2: Number of sticks in row 2\n",
    "    r3: Number of sticks in row 3\n",
    "    r4: Number of sticks in row 4\n",
    "    count: Total number of sticks left\n",
    "\"\"\"\n",
    "def setPolicy(r1, r2, r3, r4, count):\n",
    "    policy = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    for i in range(r1):\n",
    "        policy[0 + i] = 1.0/count\n",
    "    for i in range(r2):\n",
    "        policy[1 + i] = 1.0/count\n",
    "    for i in range(r3):\n",
    "        policy[4 + i] = 1.0/count\n",
    "    for i in range(r4):\n",
    "        policy[9 + i] = 1.0/count\n",
    "    return policy\n",
    "\n",
    "\"\"\"\n",
    "Generates a new policy for NIM\n",
    "\"\"\"\n",
    "def newPolicy():\n",
    "    for r1 in range(2):\n",
    "        for r2 in range(4):\n",
    "            for r3 in range(6):\n",
    "                for r4 in range(8):\n",
    "                    print((r1, r2, r3, r4), end='')\n",
    "                    print(\" : \", end='')\n",
    "                    print(setPolicy(r1, r2, r3, r4, r1 + r2 + r3 + r4), end='')\n",
    "                    print(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Observes the current state space, and makes a random legal action\n",
    "\"\"\"\n",
    "def genRandomAction(state):\n",
    "    while True: # it randomly chooses actions until it finds one that is legal\n",
    "        action = random.randint(0, 15)\n",
    "        if Policy_Template[tuple(state)][action] != 0:\n",
    "            break\n",
    "    #print(Policy_Template[tuple(state)]) # here in case we need more debugging\n",
    "    return Actions[action]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Determines which action to take based upon the PDF in Actions\n",
    "\"\"\"\n",
    "def genAction(state):\n",
    "    actionChance = random.uniform(0, 1)\n",
    "    action = 0\n",
    "    sum = 0\n",
    "    for x in Policy_Template[state]:\n",
    "        sum += x\n",
    "        if sum > actionChance: \n",
    "            break\n",
    "        else:\n",
    "            action += 1\n",
    "    return Actions[action]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Determines which action to take based on deterministic policy\n",
    "\"\"\"\n",
    "def genPolicyAction(state):\n",
    "    for i in range(16):\n",
    "        if policy[state][i] != 0:\n",
    "            return Actions[i]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Takes in a row (1, 2, 3 or 4) and removes the specified number of sticks.\n",
    "If it needs to remove more sticks than what the row contains, it terminates the program\n",
    "\"\"\"\n",
    "def Env(a, state):\n",
    "    row, nSticks = a\n",
    "    new_state = list(state)\n",
    "    if new_state[row - 1] < nSticks: # simple error check\n",
    "        print(\"Attempting to remove more sticks than possible, this shouldn't be possible!\")\n",
    "        quit()\n",
    "    else:\n",
    "        new_state[row - 1] -= nSticks # removes specified stick #\n",
    "\n",
    "    # print(new_state)\n",
    "    if (tuple(new_state) == win):\n",
    "        gameRunning == False\n",
    "        return (tuple(new_state), win_reward)\n",
    "\n",
    "    row, nSticks = genRandomAction(new_state)\n",
    "    if new_state[row - 1] < nSticks:  # simple error check\n",
    "        print(\"Attempting to remove more sticks than possible, this shouldn't be possible!\")\n",
    "        quit()\n",
    "    else:\n",
    "        new_state[row - 1] -= nSticks  # removes specified stick #\n",
    "\n",
    "    if (tuple(new_state) == win):\n",
    "        gameRunning == False\n",
    "        return (tuple(new_state), lose_reward)\n",
    "    else:\n",
    "        return (tuple(new_state), 0)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Plays the game by taking random legal moves\n",
    "\n",
    "Depreciated :(\n",
    "\"\"\"\n",
    "def genEpisodeRandomly():\n",
    "    New_Game()\n",
    "    print(state)\n",
    "    while (tuple(state) != win):\n",
    "        genRandomAction()\n",
    "        print(\"action taken\")\n",
    "        print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "play the game for on episode:\n",
    "    return States, Actions_choses, Reward, Returns\n",
    "\n",
    "do for maxrun many times\n",
    "    generate action according to policy\n",
    "    add to Actions chosen\n",
    "    Play the action - i.e., call the env to get next state and reward\n",
    "    add new state and reward to the lists\n",
    "compute Returns - comulative discounted return \n",
    "    traverse returns backward, multiply by gamma and add the next (lower index) number\n",
    "\"\"\"\n",
    "def Gen_Episode():\n",
    "    States = []\n",
    "    Actions_chosen = []\n",
    "    Reward = []\n",
    "    Return = []\n",
    "    \n",
    "    # Set initial values for state and action\n",
    "    States.append((1, 3, 5, 7))\n",
    "    Actions_chosen.append(genAction((1, 3, 5, 7)))\n",
    "    Reward.append(0)\n",
    "    Return.append(0)\n",
    "\n",
    "    # Do for maxrun steps\n",
    "    t = 0\n",
    "    while(gameRunning):\n",
    "        # Generate a reward and new state\n",
    "        next_state, rew = Env(Actions_chosen[t], States[t])\n",
    "        Reward.append(rew)\n",
    "        \n",
    "        # Assign current state to States[t]\n",
    "        States.append(next_state)\n",
    "        Return.append(0)\n",
    "        # Choose an action based on the current state\n",
    "        if (next_state != win):\n",
    "            Actions_chosen.append(genAction(next_state))\n",
    "        else:\n",
    "            Actions_chosen.append((0, 0))\n",
    "            break\n",
    "        # Increment the time variable\n",
    "        t += 1\n",
    "\n",
    "    # After intial loop, set initial return for last step\n",
    "    Return[-1] = Reward[-1]\n",
    "    # Then iterate backwards and assign rewards for each stage.\n",
    "    for r in range(t, -1, -1):\n",
    "        Return[r] = Reward[r] + Gamma * Return[r + 1]\n",
    "    return (States, Actions_chosen, Reward, Return)\n",
    "\n",
    "\"\"\"\n",
    "Helper function that takes in an action tuple and returns what it's index in the Actions dict would be\n",
    "\"\"\"\n",
    "def actionIndex(tuple):\n",
    "    for i in range(16):\n",
    "        if Actions[i] == tuple:\n",
    "            return i\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "For each state, for the the action taken, the corresponding Q value has the reward for that state/action combo added\n",
    "\"\"\"\n",
    "\n",
    "def MC_Q_Evaluate():\n",
    "    global Q\n",
    "    (States, Actions_chosen, Reward, Return) = Gen_Episode()\n",
    "    for state in States:\n",
    "        if state != (0, 0, 0, 0):  # added condition since Q value does not consider end state\n",
    "            Q[state][actionIndex(Actions_chosen[States.index( # Actions_chosen[States.index(state)] was giving tuple when int was needed. Added helper function \"actionIndex\" to create desired functionality\n",
    "                state)])] += Return[States.index(state)] # replace Reward[States.index(state)] with Return[States.index(state)]\n",
    "        #Q[r][c][Actions.index(a)] += Return[States.index((r, c))] <- original midterm code!\n",
    "\n",
    "\"\"\"\n",
    "Examines the Q table for each state and action pair. The action with the highest score for a given state will set the policy.\n",
    "\"\"\"\n",
    "def MC_find_policy(maxiter):\n",
    "    for w in range(maxiter):\n",
    "        MC_Q_Evaluate()\n",
    "\n",
    "\n",
    "    for index in Q:\n",
    "        # initializes policy to first legal action. Needed for situations where only possible move results in loss\n",
    "        optimal = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        for i in range(16):\n",
    "            if Q[index][i] != 0:\n",
    "                max = Q[index][i]\n",
    "                maxIndex = i\n",
    "                break\n",
    "\n",
    "\n",
    "        for i in range(16):\n",
    "            if Q[index][i] > max and Q[index][i] != 0:\n",
    "                max = Q[index][i]\n",
    "                maxIndex = i\n",
    "        optimal[maxIndex] = 1\n",
    "        policy[index] = optimal     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    Initialize()\n",
    "\n",
    "    #example run below\n",
    "    s, a, rew, ret = Gen_Episode()\n",
    "    for i in range(len(s)):\n",
    "        print(f\"Time: {i}\")\n",
    "        print(f\"State: {s[i]}\")\n",
    "        print(f\"Action: {a[i]}\")\n",
    "        print(f\"Reward: {rew[i]}\")\n",
    "        print(f\"Return: {ret[i]}\\n\")\n",
    "        \n",
    "    # garrett testing (he should delete this part before uploading to git)\n",
    "    #MC_Q_Evaluate()\n",
    "    MC_find_policy(1000000)\n",
    "    for x in policy:\n",
    "        print(x)\n",
    "        print(Q[x])\n",
    "        print(policy[x])\n",
    "\n",
    "    #actual runs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3d45ff1cb055de7f48204b82c6f0cd15a6d052971e23d4e794df9cb46eb817a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
